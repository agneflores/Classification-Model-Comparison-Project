{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8444769",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:35px;\">Model Performance Comparison on Imbalanced Target Data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0716632",
   "metadata": {},
   "source": [
    "<span style=\"color:navy; font-size:25px;\">Objective</span>\n",
    "\n",
    "To evaluate and compare the performance of K-Nearest Neighbors (KNN), Logistic Regression, Decision Tree, and Support Vector Machine (SVM) models on a dataset with an imbalanced target variable. The analysis focused on how each model's precision, recall, and overall accuracy metrics were affected before and after applying the SMOTE (Synthetic Minority Over-sampling Technique) to address class imbalance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d46100",
   "metadata": {},
   "source": [
    "<span style=\"color:navy; font-size:25px;\">Data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d7ff5",
   "metadata": {},
   "source": [
    "[Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \n",
    "  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\n",
    "\n",
    "  Available at: [pdf] http://hdl.handle.net/1822/14838\n",
    "                [bib] http://www3.dsi.uminho.pt/pcortez/bib/2011-esm-1.txt\n",
    "\n",
    "1. Title: Bank Marketing\n",
    "\n",
    "2. Sources\n",
    "   Created by: Paulo Cortez (Univ. Minho) and Sérgio Moro (ISCTE-IUL) @ 2012\n",
    "   \n",
    "3. Past Usage:\n",
    "\n",
    "The full dataset was described and analyzed in:\n",
    "\n",
    "S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \n",
    "In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, \n",
    "Portugal, October, 2011. EUROSIS.\n",
    "\n",
    "4. Relevant Information:\n",
    "\n",
    "   The data is related with direct marketing campaigns of a Portuguese banking institution. \n",
    "   The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, \n",
    "   in order to access if the product (bank term deposit) would be (or not) subscribed. \n",
    "\n",
    "   There are two datasets: \n",
    "      1) bank-full.csv with all examples, ordered by date (from May 2008 to November 2010).\n",
    "      2) bank.csv with 10% of the examples (4521), randomly selected from bank-full.csv.\n",
    "   The smallest dataset is provided to test more computationally demanding machine learning algorithms (e.g. SVM).\n",
    "\n",
    "   The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "5. Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\n",
    "\n",
    "6. Number of Attributes: 16 + output attribute.\n",
    "\n",
    "7. Attribute information:\n",
    "\n",
    "   For more information, read [Moro et al., 2011].\n",
    "\n",
    "   Input variables:\n",
    "   \n",
    "   ## Bank client data:\n",
    "   \n",
    "age: (numeric)\n",
    "   \n",
    "job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "                                       \n",
    "marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "   \n",
    "education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "   \n",
    "default: has credit in default? (binary: \"yes\",\"no\")\n",
    "   \n",
    "balance: average yearly balance, in euros (numeric) \n",
    "   \n",
    "housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "   \n",
    "loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "   \n",
    "   ## Related with the last contact of the current campaign:\n",
    "   \n",
    "contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "   \n",
    "day: last contact day of the month (numeric)\n",
    "  \n",
    "month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "  \n",
    "duration: last contact duration, in seconds (numeric)\n",
    "  \n",
    "   ## Other attributes:\n",
    "   \n",
    "campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "  \n",
    "pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "  \n",
    "previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "  \n",
    "poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "  #### Target variable:\n",
    "  \n",
    "y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
    "\n",
    "8. Missing Attribute Values: None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df4fee",
   "metadata": {},
   "source": [
    "<span style=\"color:navy; font-size:25px;\">Data Investigation & Preparation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b2dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab65cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d4776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  age           job  marital  education default balance housing loan  contact  \\\n",
      "0  58    management  married   tertiary      no    2143     yes   no  unknown   \n",
      "1  44    technician   single  secondary      no      29     yes   no  unknown   \n",
      "2  33  entrepreneur  married  secondary      no       2     yes  yes  unknown   \n",
      "3  47   blue-collar  married    unknown      no    1506     yes   no  unknown   \n",
      "4  33       unknown   single    unknown      no       1      no   no  unknown   \n",
      "\n",
      "  day month duration campaign pdays previous poutcome   y  \n",
      "0   5   may      261        1    -1        0  unknown  no  \n",
      "1   5   may      151        1    -1        0  unknown  no  \n",
      "2   5   may       76        1    -1        0  unknown  no  \n",
      "3   5   may       92        1    -1        0  unknown  no  \n",
      "4   5   may      198        1    -1        0  unknown  no  \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV data using the csv module\n",
    "file_path = r'C:\\Users\\agnek\\OneDrive\\Documents\\Educational_Training Materials\\Berkeley Haas\\Codio\\Module17\\Bank_Marketing.csv'\n",
    "\n",
    "with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "    # Extract the first line (headers) and split based on the semicolon delimiter\n",
    "    headers = file.readline().strip().split(';')\n",
    "    headers = [h.replace('\"', '') for h in headers]  # Remove any extra quotes\n",
    "    \n",
    "    # Use a list to hold the rows of data\n",
    "    data = []\n",
    "    \n",
    "    # Read the rest of the rows in the file\n",
    "    for line in file:\n",
    "        # Split each line on the semicolon delimiter\n",
    "        row = line.strip().split(';')\n",
    "        row = [r.replace('\"', '') for r in row]  # Clean any extra quotes\n",
    "        data.append(row)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088b8106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age           job  marital  education default balance housing loan  contact  \\\n",
       "0  58    management  married   tertiary      no    2143     yes   no  unknown   \n",
       "1  44    technician   single  secondary      no      29     yes   no  unknown   \n",
       "2  33  entrepreneur  married  secondary      no       2     yes  yes  unknown   \n",
       "3  47   blue-collar  married    unknown      no    1506     yes   no  unknown   \n",
       "4  33       unknown   single    unknown      no       1      no   no  unknown   \n",
       "\n",
       "  day month duration campaign pdays previous poutcome   y  \n",
       "0   5   may      261        1    -1        0  unknown  no  \n",
       "1   5   may      151        1    -1        0  unknown  no  \n",
       "2   5   may       76        1    -1        0  unknown  no  \n",
       "3   5   may       92        1    -1        0  unknown  no  \n",
       "4   5   may      198        1    -1        0  unknown  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ab283",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "#### Manually Handling the Header:\n",
    "\n",
    "We read the first line (header) using file.readline() and split it manually on the semicolon delimiter.\n",
    "Quotes are removed from the header elements using a list comprehension.\n",
    "\n",
    "#### Reading Data Rows:\n",
    "\n",
    "Each subsequent line is read, stripped of leading/trailing whitespace, and split based on the semicolon delimiter.\n",
    "Quotes are removed from each element of the row before appending it to the data list.\n",
    "\n",
    "#### Creating the DataFrame:\n",
    "\n",
    "The cleaned data is then passed into a pandas.DataFrame() along with the cleaned headers to create the DataFrame.\n",
    "\n",
    "#### Result:\n",
    "\n",
    "The df.head() command should now print the first few rows of your DataFrame, correctly formatted without any column mismatch errors.\n",
    "\n",
    "### Why This Works:\n",
    "This approach directly addresses any inconsistencies in how the CSV file might be structured or how delimiters are handled, ensuring that each row is properly split and cleaned before being added to the DataFrame.\n",
    "\n",
    "By manually processing the file line by line, we have more control over how the data is parsed, which helps avoid issues that might arise with the csv.reader in cases where the data structure is non-standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cdda3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  object\n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  object\n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  object\n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  object\n",
      " 12  campaign   45211 non-null  object\n",
      " 13  pdays      45211 non-null  object\n",
      " 14  previous   45211 non-null  object\n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Doublecheck for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93d8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert object data types for numeric columns into int64\n",
    "df[['age', 'balance', 'day','duration','campaign','pdays','previous']] = df[['age', 'balance', 'day','duration','campaign','pdays','previous']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b5dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf4f946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>2143</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>29</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1506</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education  balance  contact  day month  \\\n",
       "0   58    management  married   tertiary     2143  unknown    5   may   \n",
       "1   44    technician   single  secondary       29  unknown    5   may   \n",
       "2   33  entrepreneur  married  secondary        2  unknown    5   may   \n",
       "3   47   blue-collar  married    unknown     1506  unknown    5   may   \n",
       "4   33       unknown   single    unknown        1  unknown    5   may   \n",
       "\n",
       "   duration  campaign  pdays  previous poutcome  default_yes  housing_yes  \\\n",
       "0       261         1     -1         0  unknown            0            1   \n",
       "1       151         1     -1         0  unknown            0            1   \n",
       "2        76         1     -1         0  unknown            0            1   \n",
       "3        92         1     -1         0  unknown            0            1   \n",
       "4       198         1     -1         0  unknown            0            0   \n",
       "\n",
       "   loan_yes  y_yes  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         1      0  \n",
       "3         0      0  \n",
       "4         0      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pd.get_dummies for binary variables\n",
    "df = pd.get_dummies(df, columns=['default', 'housing', 'loan','y'], drop_first=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa24ecf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2143</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1506</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  day  duration  campaign  pdays  previous  default_yes  \\\n",
       "0   58     2143    5       261         1     -1         0            0   \n",
       "1   44       29    5       151         1     -1         0            0   \n",
       "2   33        2    5        76         1     -1         0            0   \n",
       "3   47     1506    5        92         1     -1         0            0   \n",
       "4   33        1    5       198         1     -1         0            0   \n",
       "\n",
       "   housing_yes  loan_yes  ...  month_jul  month_jun  month_mar  month_may  \\\n",
       "0            1         0  ...        0.0        0.0        0.0        1.0   \n",
       "1            1         0  ...        0.0        0.0        0.0        1.0   \n",
       "2            1         1  ...        0.0        0.0        0.0        1.0   \n",
       "3            1         0  ...        0.0        0.0        0.0        1.0   \n",
       "4            0         0  ...        0.0        0.0        0.0        1.0   \n",
       "\n",
       "   month_nov  month_oct  month_sep  poutcome_other  poutcome_success  \\\n",
       "0        0.0        0.0        0.0             0.0               0.0   \n",
       "1        0.0        0.0        0.0             0.0               0.0   \n",
       "2        0.0        0.0        0.0             0.0               0.0   \n",
       "3        0.0        0.0        0.0             0.0               0.0   \n",
       "4        0.0        0.0        0.0             0.0               0.0   \n",
       "\n",
       "   poutcome_unknown  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_df = pd.DataFrame(encoder.fit_transform(df[['job', 'marital', 'education', 'contact', 'month', 'poutcome']]),\n",
    "                          columns=encoder.get_feature_names_out(['job', 'marital', 'education', 'contact', 'month', 'poutcome']))\n",
    "\n",
    "# Concatenate with the original DataFrame (excluding original categorical columns)\n",
    "df_encoded = pd.concat([df.drop(['job', 'marital', 'education', 'contact', 'month', 'poutcome'], axis=1), encoded_df], axis=1)\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd144a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 43 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   age                  45211 non-null  int64  \n",
      " 1   balance              45211 non-null  int64  \n",
      " 2   day                  45211 non-null  int64  \n",
      " 3   duration             45211 non-null  int64  \n",
      " 4   campaign             45211 non-null  int64  \n",
      " 5   pdays                45211 non-null  int64  \n",
      " 6   previous             45211 non-null  int64  \n",
      " 7   default_yes          45211 non-null  uint8  \n",
      " 8   housing_yes          45211 non-null  uint8  \n",
      " 9   loan_yes             45211 non-null  uint8  \n",
      " 10  y_yes                45211 non-null  uint8  \n",
      " 11  job_blue-collar      45211 non-null  float64\n",
      " 12  job_entrepreneur     45211 non-null  float64\n",
      " 13  job_housemaid        45211 non-null  float64\n",
      " 14  job_management       45211 non-null  float64\n",
      " 15  job_retired          45211 non-null  float64\n",
      " 16  job_self-employed    45211 non-null  float64\n",
      " 17  job_services         45211 non-null  float64\n",
      " 18  job_student          45211 non-null  float64\n",
      " 19  job_technician       45211 non-null  float64\n",
      " 20  job_unemployed       45211 non-null  float64\n",
      " 21  job_unknown          45211 non-null  float64\n",
      " 22  marital_married      45211 non-null  float64\n",
      " 23  marital_single       45211 non-null  float64\n",
      " 24  education_secondary  45211 non-null  float64\n",
      " 25  education_tertiary   45211 non-null  float64\n",
      " 26  education_unknown    45211 non-null  float64\n",
      " 27  contact_telephone    45211 non-null  float64\n",
      " 28  contact_unknown      45211 non-null  float64\n",
      " 29  month_aug            45211 non-null  float64\n",
      " 30  month_dec            45211 non-null  float64\n",
      " 31  month_feb            45211 non-null  float64\n",
      " 32  month_jan            45211 non-null  float64\n",
      " 33  month_jul            45211 non-null  float64\n",
      " 34  month_jun            45211 non-null  float64\n",
      " 35  month_mar            45211 non-null  float64\n",
      " 36  month_may            45211 non-null  float64\n",
      " 37  month_nov            45211 non-null  float64\n",
      " 38  month_oct            45211 non-null  float64\n",
      " 39  month_sep            45211 non-null  float64\n",
      " 40  poutcome_other       45211 non-null  float64\n",
      " 41  poutcome_success     45211 non-null  float64\n",
      " 42  poutcome_unknown     45211 non-null  float64\n",
      "dtypes: float64(32), int64(7), uint8(4)\n",
      "memory usage: 13.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a70feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y counts:\n",
      " 0    39922\n",
      "1     5289\n",
      "Name: y_yes, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class proportions:\n",
      " 0    0.883015\n",
      "1    0.116985\n",
      "Name: y_yes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Examine the target variable\n",
    "y_counts = df_encoded['y_yes'].value_counts()\n",
    "print(\"y counts:\\n\", y_counts)\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "y_counts.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show()\n",
    "\n",
    "# Calculate class proportions\n",
    "y_proportions = df_encoded['y_yes'].value_counts(normalize=True)\n",
    "print(\"Class proportions:\\n\", y_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a5712b",
   "metadata": {},
   "source": [
    "<span style=\"color:navy; font-size:25px;\">Modeling & Evaluation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee6230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and y\n",
    "X = df_encoded.drop('y_yes', axis=1)\n",
    "y = df_encoded['y_yes']\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74aa9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features (this will also address the negative value issue in pday column)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee419c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red; font-size:25px;\">KNN Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3b0dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     11966\n",
      "           1       0.55      0.35      0.43      1598\n",
      "\n",
      "    accuracy                           0.89     13564\n",
      "   macro avg       0.73      0.66      0.68     13564\n",
      "weighted avg       0.87      0.89      0.88     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"K-Nearest Neighbors:\")\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95743b7",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "#### Imbalance Issue: \n",
    "The dataset is highly imbalanced, with a much larger number of class 0 instances compared to class 1. This imbalance is reflected in the model's performance, where it performs very well on the majority class (class 0) but struggles with the minority class (class 1).\n",
    "\n",
    "#### Poor Performance on Minority Class: \n",
    "The precision, recall, and F1-score for class 1 are significantly lower than those for class 0. This indicates that the model is not effectively identifying class 1 instances, which is a common issue in imbalanced datasets.\n",
    "\n",
    "#### High Accuracy but Misleading: \n",
    "The overall accuracy of 0.89 seems high, but it is primarily driven by the model's performance on the majority class. Given the poor performance on class 1, accuracy alone does not provide a complete picture of the model’s effectiveness.\n",
    "\n",
    "### Potential Improvements:\n",
    "\n",
    "#### Resampling Techniques: \n",
    "Consider using oversampling techniques like SMOTE (Synthetic Minority Over-sampling Technique) or undersampling the majority class to balance the dataset.\n",
    "\n",
    "#### Adjust Class Weights: \n",
    "Implementing class weights in the KNN model or trying models that naturally handle imbalanced data better, such as Random Forests with class weighting.\n",
    "\n",
    "#### Threshold Tuning: \n",
    "Adjust the decision threshold for class 1 to improve recall, although this may impact precision.\n",
    "\n",
    "### Conclusion:\n",
    "The KNN model performs well on the majority class but struggles with the minority class due to the imbalanced nature of the dataset. To improve the model's performance on the minority class, especially in applications where correctly identifying class 1 is critical, techniques to address class imbalance should be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09b757",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### KNN with SMOTE\n",
    "\n",
    "First, make sure you have the imbalanced-learn library installed. You can install it using pip:\n",
    "\n",
    "#### pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6673809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install required library\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9a141c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original target class distribution:\n",
      "0    27956\n",
      "1     3691\n",
      "Name: y_yes, dtype: int64\n",
      "\n",
      "Resampled target class distribution:\n",
      "0    27956\n",
      "1    27956\n",
      "Name: y_yes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the balance of the resampled data\n",
    "print(\"Original target class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nResampled target class distribution:\")\n",
    "print(y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "## Apply undersampling to the training data\n",
    "#undersampler = RandomUnderSampler(random_state=42)\n",
    "#X_train_res, y_train_res = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "## Check the balance of the resampled data\n",
    "#print(\"Original target class distribution:\")\n",
    "#print(y_train.value_counts())\n",
    "\n",
    "#print(\"\\nResampled target class distribution:\")\n",
    "#print(y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.combine import SMOTEENN\n",
    "\n",
    "## Combine SMOTE with undersampling using SMOTEENN\n",
    "#smote_enn = SMOTEENN(random_state=42)\n",
    "#X_train_res, y_train_res = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "## Check the balance of the resampled data\n",
    "#print(\"Original target class distribution:\")\n",
    "#print(y_train.value_counts())\n",
    "\n",
    "#print(\"\\nResampled target class distribution:\")\n",
    "#print(y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9691f6",
   "metadata": {},
   "source": [
    "Summary:\n",
    "SMOTE: Generates synthetic samples for the minority class to balance the dataset.\n",
    "Undersampling: Reduces the number of samples in the majority class to balance the dataset.\n",
    "Combined Techniques: Methods like SMOTEENN and SMOTETomek combine oversampling and undersampling to achieve better balance.\n",
    "These techniques help to address class imbalance, leading to more robust and fair models. However, it’s essential to evaluate the impact of these techniques on your model’s performance, as they can sometimes introduce noise or remove important instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d31d7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91     11966\n",
      "           1       0.41      0.63      0.50      1598\n",
      "\n",
      "    accuracy                           0.85     13564\n",
      "   macro avg       0.68      0.75      0.70     13564\n",
      "weighted avg       0.88      0.85      0.86     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the model using the resampled data\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ee23d",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "#### Improvement for Class 1: \n",
    "SMOTE successfully improved the model's ability to detect class 1 (minority class), as evidenced by the significant increase in recall from 0.35 to 0.63. This means the model is now better at identifying true positives for the minority class.\n",
    "\n",
    "#### Trade-offs: \n",
    "While recall for class 1 improved, precision for class 1 decreased, leading to more false positives. This trade-off is common when applying SMOTE, as the model becomes more inclusive in identifying the minority class, sometimes at the cost of precision.\n",
    "\n",
    "#### Overall Balance: \n",
    "The macro average metrics show that the model's ability to handle both classes more equitably improved, with better recall but slightly lower precision.\n",
    "\n",
    "### Conclusion:\n",
    "After applying SMOTE, the KNN model became more effective at identifying the minority class (class 1), as seen by the improved recall and F1-score for class 1. However, this came at the cost of reduced precision for class 1 and a slight drop in overall accuracy. The application of SMOTE made the model more balanced in handling both classes, which is particularly useful in scenarios where detecting the minority class is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c8d55",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red; font-size:25px;\">Logistic Regression Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3359ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91     11966\n",
      "           1       0.42      0.82      0.56      1598\n",
      "\n",
      "    accuracy                           0.85     13564\n",
      "   macro avg       0.70      0.84      0.73     13564\n",
      "weighted avg       0.91      0.85      0.87     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=200, class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78672c07",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "#### Class Imbalance Handling:\n",
    "\n",
    "The model shows a decent recall for both classes, particularly for the minority class (class 1). This indicates that the logistic regression model is reasonably sensitive to class 1, which is a good sign for imbalanced datasets.\n",
    "However, the low precision for class 1 (0.42) indicates that many instances predicted as class 1 are actually class 0, leading to a higher number of false positives.\n",
    "\n",
    "#### Model Performance:\n",
    "\n",
    "The high recall and low precision for class 1 suggest that the model is more concerned with capturing all possible positive instances, even at the cost of increasing false positives. This trade-off might be acceptable depending on the application; for example, in cases where it's more critical to identify all positives (class 1) even if some negatives (class 0) are incorrectly identified as positives.\n",
    "\n",
    "The overall accuracy of 0.85 is strong but might not fully reflect the model's performance on the minority class.\n",
    "\n",
    "### Potential Improvements:\n",
    "\n",
    "#### Threshold Adjustment: \n",
    "Adjusting the decision threshold for class 1 could help improve precision at the cost of recall. This would be useful if the application requires higher confidence in positive predictions.\n",
    "\n",
    "#### Alternative Models: \n",
    "Exploring more complex models such as Random Forests or Gradient Boosting Machines (GBMs) that might handle imbalanced datasets more effectively.\n",
    "\n",
    "#### Class Weights: \n",
    "Logistic regression allows for class weights. You might consider fine-tuning the class weights to improve precision for the minority class.\n",
    "\n",
    "### Conclusion:\n",
    "The logistic regression model performs well in terms of overall recall, particularly for the minority class. However, the low precision for class 1 suggests that the model produces a relatively high number of false positives. Depending on the application, this trade-off may be acceptable, but further tuning or the use of more advanced techniques might be necessary to improve the model's performance, particularly in scenarios where false positives are costly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85947dfe",
   "metadata": {},
   "source": [
    "### Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79d23c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression after SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91     11966\n",
      "           1       0.42      0.82      0.56      1598\n",
      "\n",
      "    accuracy                           0.85     13564\n",
      "   macro avg       0.70      0.83      0.73     13564\n",
      "weighted avg       0.91      0.85      0.87     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression after SMOTE:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a201d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style=\"color:red; font-size:25px;\">Decision Tree Classifier</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e45ef4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     11966\n",
      "           1       0.47      0.45      0.46      1598\n",
      "\n",
      "    accuracy                           0.87     13564\n",
      "   macro avg       0.70      0.69      0.69     13564\n",
      "weighted avg       0.87      0.87      0.87     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(class_weight='balanced')\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(classification_report(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87686fdd",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "#### Imbalance Issue:\n",
    "\n",
    "The model performs well on the majority class (class 0), with high precision, recall, and F1-score. However, it struggles with the minority class (class 1), as seen by the lower precision (0.47) and recall (0.45). This is a common issue when dealing with imbalanced datasets, where the model tends to favor the majority class.\n",
    "\n",
    "#### Class 1 Performance:\n",
    "\n",
    "The low precision for class 1 indicates that many instances predicted as class 1 are actually class 0 (false positives). The low recall indicates that the model is missing a significant portion of the actual class 1 instances (false negatives). This results in a low F1-score of 0.46, which reflects the poor performance in classifying the minority class.\n",
    "\n",
    "#### Overall Accuracy:\n",
    "\n",
    "The accuracy of 0.87 is good, but it is primarily driven by the model's performance on the majority class. This highlights the limitations of using accuracy as a sole metric, especially when dealing with imbalanced datasets.\n",
    "\n",
    "### Potential Improvements:\n",
    "\n",
    "#### Resampling Techniques: \n",
    "Consider using oversampling (e.g., SMOTE) for class 1 or undersampling for class 0 to balance the classes more effectively.\n",
    "\n",
    "#### Adjusting Class Weights: \n",
    "Decision Trees can incorporate class weights to penalize misclassification of the minority class. Adjusting these weights could help improve the model's performance on class 1.\n",
    "\n",
    "#### Tree Pruning or Depth Limitation: \n",
    "Pruning the tree or limiting its depth can reduce overfitting to the majority class, potentially improving generalization to the minority class.\n",
    "\n",
    "#### Alternative Models: \n",
    "Consider using ensemble methods like Random Forests or Gradient Boosting Machines, which often handle class imbalance better than single Decision Trees.\n",
    "\n",
    "### Conclusion:\n",
    "The Decision Tree model performs well on the majority class but struggles with the minority class due to the imbalance in the dataset. While the overall accuracy is good, the model's performance on the minority class is lacking, as indicated by the lower precision, recall, and F1-score for class 1. Addressing the class imbalance through resampling techniques, adjusting class weights, or using more sophisticated models may improve the model's ability to correctly identify the minority class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a061be",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d38b170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier after SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     11966\n",
      "           1       0.42      0.53      0.47      1598\n",
      "\n",
      "    accuracy                           0.86     13564\n",
      "   macro avg       0.68      0.72      0.69     13564\n",
      "weighted avg       0.87      0.86      0.86     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Decision Tree Classifier using the resampled data\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Classifier after SMOTE:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f4a6a",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "#### Improvement for Class 1: \n",
    "The recall for class 1 improved significantly from 0.45 to 0.53 after SMOTE was applied, meaning that the model became better at identifying the minority class. This is a positive outcome of using SMOTE.\n",
    "\n",
    "#### Trade-offs: \n",
    "The improvement in recall for class 1 came with a slight decrease in precision for class 1, indicating more false positives. Additionally, the slight decrease in recall for class 0 is a typical trade-off when balancing an imbalanced dataset.\n",
    "\n",
    "#### Overall Balance: \n",
    "The macro average recall improved, which indicates that the model became more balanced in its ability to detect both classes. However, the overall accuracy and precision for class 1 slightly decreased, which is a typical consequence of applying SMOTE.\n",
    "\n",
    "### Conclusion:\n",
    "After applying SMOTE, the Decision Tree model became more effective at identifying the minority class (class 1) by improving its recall. However, this improvement came with a slight decrease in precision for class 1 and a marginal drop in overall accuracy. The model now has a better balance in handling both classes, making it more suitable for situations where identifying the minority class is crucial, even if it comes at the cost of some overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35040fe3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red; font-size:25px;\">Support Vector Machine</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4da54732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91     11966\n",
      "           1       0.43      0.86      0.57      1598\n",
      "\n",
      "    accuracy                           0.85     13564\n",
      "   macro avg       0.70      0.85      0.74     13564\n",
      "weighted avg       0.91      0.85      0.87     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Support Vector Machine:\")\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ca094",
   "metadata": {},
   "source": [
    "### Overall Metrics:\n",
    "#### Accuracy: 0.85\n",
    "The overall accuracy of 0.85 indicates that 85% of all instances were correctly classified. However, as previously discussed, accuracy alone can be misleading, especially with imbalanced datasets.\n",
    "\n",
    "#### Macro Average:\n",
    "Precision: 0.70\n",
    "Recall: 0.85\n",
    "F1-Score: 0.74\n",
    "The macro average is the unweighted average of the metrics for each class. It treats both classes equally, showing that the model generally favors recall over precision.\n",
    "\n",
    "#### Weighted Average:\n",
    "Precision: 0.91\n",
    "Recall: 0.85\n",
    "F1-Score: 0.87\n",
    "The weighted average takes into account the support (number of instances) of each class, so it’s more influenced by the majority class (class 0). These metrics reflect good overall performance but are heavily skewed by the model’s performance on the majority class.\n",
    "\n",
    "### Analysis:\n",
    "\n",
    "#### Imbalance Issue:\n",
    "\n",
    "The model handles the minority class (class 1) better in terms of recall, with a high recall score of 0.86. This indicates that the model is quite effective at identifying the minority class, which is often challenging in imbalanced datasets.\n",
    "However, the low precision for class 1 (0.43) suggests that many instances predicted as class 1 are actually class 0, resulting in a high number of false positives.\n",
    "\n",
    "#### Trade-off Between Precision and Recall:\n",
    "\n",
    "The SVM model appears to be prioritizing recall over precision for class 1, capturing most of the actual positives but at the cost of many incorrect positive predictions. This may be acceptable depending on the application—especially in scenarios where missing a positive instance is more costly than having false positives.\n",
    "The overall F1-score for class 1 is moderate (0.57), indicating a trade-off between precision and recall.\n",
    "\n",
    "#### Class 0 Performance:\n",
    "\n",
    "The model performs exceptionally well for class 0, with very high precision (0.98) and a solid recall (0.85). The F1-score of 0.91 reflects strong overall performance for the majority class, which is consistent with the model's behavior in imbalanced datasets.\n",
    "\n",
    "#### Accuracy Considerations:\n",
    "\n",
    "The overall accuracy of 0.85 is good but does not fully capture the model’s performance, particularly on the minority class. The imbalance in precision and recall for class 1 highlights the limitations of relying solely on accuracy.\n",
    "\n",
    "### Potential Improvements:\n",
    "\n",
    "#### Threshold Adjustment: \n",
    "Adjusting the decision threshold for class 1 could help improve precision at the cost of recall. This would be useful in applications where precision is more critical.\n",
    "\n",
    "#### Class Weights: \n",
    "SVM models can incorporate class weights to penalize misclassification of the minority class, potentially improving precision for class 1.\n",
    "\n",
    "#### Resampling Techniques: \n",
    "Consider using oversampling (e.g., SMOTE) for class 1 or undersampling for class 0 to balance the dataset more effectively.\n",
    "\n",
    "#### Ensemble Methods: \n",
    "Trying ensemble methods like Random Forests or Gradient Boosting Machines may offer better handling of class imbalance.\n",
    "\n",
    "### Conclusion:\n",
    "The SVM model shows strong overall performance, particularly in identifying the minority class (class 1), as reflected by the high recall (0.86). However, the low precision (0.43) for class 1 indicates a significant number of false positives, which may be problematic depending on the application. While the accuracy is good, it doesn't fully reflect the model's performance on the minority class. Adjustments to the model, such as tuning the decision threshold or adjusting class weights, may be necessary to improve the balance between precision and recall for class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94b562",
   "metadata": {},
   "source": [
    "### Support Vector Machine after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a41a5297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM after SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92     11966\n",
      "           1       0.44      0.79      0.57      1598\n",
      "\n",
      "    accuracy                           0.86     13564\n",
      "   macro avg       0.71      0.83      0.74     13564\n",
      "weighted avg       0.91      0.86      0.87     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the SVM model using the resampled data\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM after SMOTE:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394d452",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "#### Improvement for Class 0: \n",
    "The model's recall for class 0 slightly improved after SMOTE, resulting in a small increase in F1-score. Precision remained high, but with a very slight decrease.\n",
    "\n",
    "#### Class 1 Stability: \n",
    "The performance metrics for class 1 (minority class) remained relatively stable, with only minor changes in precision and recall. This suggests that SMOTE did not significantly alter the model's ability to predict class 1, which could be due to how the SVM algorithm handles the synthetic data.\n",
    "\n",
    "#### Overall Stability: \n",
    "The overall metrics (accuracy, macro average, and weighted average) remained stable, with minor improvements in some areas. The model continued to perform well after applying SMOTE, but the expected significant improvements in recall for class 1 were not observed.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Applying SMOTE to the SVM model resulted in slight improvements in recall for class 0 and a slight increase in overall accuracy. However, the expected improvements in recall for class 1 were not as pronounced, and the precision for class 1 remained similar. The SVM model appears to be robust to the application of SMOTE, maintaining strong overall performance while handling the synthetic data effectively. The overall impact of SMOTE on this SVM model was minimal, indicating that the model was already performing well on the imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd852550",
   "metadata": {},
   "source": [
    "### Executive Summary & Conclusion\n",
    "\n",
    "Based on the analysis of the results before and after applying SMOTE for the KNN, Decision Tree, and SVM models (and considering that Logistic Regression results did not change significantly), here’s a summary to help decide which model is the best:\n",
    "\n",
    "1. K-Nearest Neighbors (KNN)\n",
    "\n",
    "Before SMOTE:\n",
    "Class 1 Recall: 0.35 (Low)\n",
    "Class 1 Precision: 0.55 (Moderate)\n",
    "Overall Accuracy: 0.89\n",
    "\n",
    "After SMOTE:\n",
    "Class 1 Recall: 0.63 (Significant Improvement)\n",
    "Class 1 Precision: 0.41 (Decreased)\n",
    "Overall Accuracy: 0.85 (Slight Decrease)\n",
    "\n",
    "2. Decision Tree\n",
    "\n",
    "Before SMOTE:\n",
    "Class 1 Recall: 0.45 (Moderate)\n",
    "Class 1 Precision: 0.47 (Moderate)\n",
    "Overall Accuracy: 0.87\n",
    "\n",
    "After SMOTE:\n",
    "Class 1 Recall: 0.53 (Moderate Improvement)\n",
    "Class 1 Precision: 0.42 (Slight Decrease)\n",
    "Overall Accuracy: 0.86 (Slight Decrease)\n",
    "\n",
    "3. Support Vector Machine (SVM)\n",
    "\n",
    "Before SMOTE:\n",
    "Class 1 Recall: 0.86 (High)\n",
    "Class 1 Precision: 0.43 (Moderate)\n",
    "Overall Accuracy: 0.85\n",
    "\n",
    "After SMOTE:\n",
    "Class 1 Recall: 0.79 (Slight Decrease)\n",
    "Class 1 Precision: 0.44 (Slight Increase)\n",
    "Overall Accuracy: 0.86 (Slight Increase)\n",
    "\n",
    "### Conclusion Summary:\n",
    "\n",
    "When comparing the performance of K-Nearest Neighbors (KNN), Logistic Regression, Decision Tree, and Support Vector Machine (SVM) models on imbalanced data, we observed that the application of SMOTE had varying impacts across the models.\n",
    "\n",
    "K-Nearest Neighbors (KNN) showed a significant improvement in recall for class 1 after applying SMOTE, but this came at the cost of decreased precision and overall accuracy. While the model became more sensitive to the minority class, it also became more prone to false positives.\n",
    "\n",
    "Logistic Regression maintained consistent performance before and after applying SMOTE, with high recall for class 1 and moderate precision. The identical results suggest that the class_weight='balanced' parameter effectively handled the class imbalance, making SMOTE redundant for this model.\n",
    "\n",
    "Decision Tree experienced a moderate improvement in recall after SMOTE was applied, but this was offset by a slight decrease in precision and overall accuracy. The model's sensitivity to the minority class improved, but it became less precise in identifying true positives.\n",
    "\n",
    "Support Vector Machine (SVM) had the highest recall for class 1 before SMOTE, with a slight decrease in recall and a marginal increase in precision after SMOTE. The overall accuracy improved slightly, indicating that SVM maintained robust performance even with the application of SMOTE.\n",
    "\n",
    "### Best Model Selection:\n",
    "Support Vector Machine (SVM) is the best model for this scenario.\n",
    "\n",
    "### Justification:\n",
    "\n",
    "#### High Initial Recall: \n",
    "SVM already exhibited the highest recall for class 1 before applying SMOTE, indicating strong performance in identifying the minority class.\n",
    "#### Balanced Performance After SMOTE: \n",
    "While there was a slight decrease in recall after SMOTE, SVM still maintained a high level of recall with a slight increase in precision and overall accuracy. This balance makes it a reliable choice for scenarios where both sensitivity to the minority class and overall accuracy are critical.\n",
    "#### Robustness: \n",
    "SVM's ability to maintain strong performance with minimal changes after SMOTE demonstrates its robustness in handling imbalanced datasets effectively without significant degradation in other metrics.\n",
    "\n",
    "Given these considerations, the SVM model offers the best combination of high recall, balanced precision, and stable overall accuracy, making it the most suitable choice for dealing with imbalanced target data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ddf74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
